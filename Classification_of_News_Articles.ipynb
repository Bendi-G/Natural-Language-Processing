{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Articles\n",
    "The data consists of a collection of articles on topics, including baseball, cryptography, electronics, hardware, medicine, mideast, motorcycles, politics, religion, and space. The posts are extracted from the 20 Newsgroups dataset.\n",
    "\n",
    "This notebook do the preprocessing, and predicts the topics from this collection of texts using a supervised machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "import en_core_web_md\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data\n",
    "X = pd.read_csv(\"data/X_train.csv\")\n",
    "y = pd.read_csv(\"data/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (6384, 1)\n",
      "y_shape: (6384, 1)\n",
      "n_categories: 10\n",
      "categories: ['baseball' 'cryptography' 'electronics' 'hardware' 'medicine' 'mideast'\n",
      " 'motorcycles' 'politics' 'religion' 'space']\n"
     ]
    }
   ],
   "source": [
    "## Look at the data\n",
    "\n",
    "print('X_shape: {}'.format(X.shape))\n",
    "print('y_shape: {}'.format(y.shape))\n",
    "print('n_categories: {}'.format(y['label'].nunique()))\n",
    "print('categories: {}'.format(y['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into random train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spacy tokenizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def spacy_tokenizer(text):\n",
    "    tokens = nlp(text)\n",
    "    tokens = [tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\n",
    "    tokens = [tok for tok in tokens if (tok not in stopwords and tok not in punctuations)]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorizer with above spacy and Scikit learn\n",
    "\n",
    "preprocessor = ColumnTransformer([(\"processing\", TfidfVectorizer(tokenizer=spacy_tokenizer), \"text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9226388229710489\n",
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'alpha': (0.05, 0.07, 0.1), 'fit_prior': [True, False]}\n",
    "clf = GridSearchCV(MultinomialNB(), parameters, cv=3)\n",
    "\n",
    "model = Pipeline([(\"preprocessor\", preprocessor), (\"model\", clf)]).fit(X_train,y_train['label'])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "score_grid_MNB = accuracy_score(y_test['label'], y_pred)\n",
    "\n",
    "print(score_grid_MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9245372567631703\n"
     ]
    }
   ],
   "source": [
    "## Vectorizer without spacy and pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75,1),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__alpha': (0.07, 0.08, 0.09, 0.1),\n",
    "    'clf__fit_prior': [True, False]}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3)\n",
    "grid_search_tune.fit(X_train['text'], y_train['label'])\n",
    "\n",
    "\n",
    "y_pred_pipe = grid_search_tune.predict(X_test['text'])\n",
    "score_pip = accuracy_score(y_test['label'], y_pred_pipe)\n",
    "\n",
    "print(score_pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
